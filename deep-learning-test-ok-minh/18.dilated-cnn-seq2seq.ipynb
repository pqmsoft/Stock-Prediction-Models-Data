{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dev\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.compat.v1.random.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>778.200012</td>\n",
       "      <td>781.650024</td>\n",
       "      <td>763.450012</td>\n",
       "      <td>768.700012</td>\n",
       "      <td>768.700012</td>\n",
       "      <td>1872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>767.250000</td>\n",
       "      <td>769.950012</td>\n",
       "      <td>759.030029</td>\n",
       "      <td>762.130005</td>\n",
       "      <td>762.130005</td>\n",
       "      <td>1943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>750.659973</td>\n",
       "      <td>770.359985</td>\n",
       "      <td>750.560974</td>\n",
       "      <td>762.020020</td>\n",
       "      <td>762.020020</td>\n",
       "      <td>2134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>774.500000</td>\n",
       "      <td>785.190002</td>\n",
       "      <td>772.549988</td>\n",
       "      <td>782.520020</td>\n",
       "      <td>782.520020</td>\n",
       "      <td>1585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>783.400024</td>\n",
       "      <td>795.632996</td>\n",
       "      <td>780.190002</td>\n",
       "      <td>790.510010</td>\n",
       "      <td>790.510010</td>\n",
       "      <td>1350800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2016-11-02  778.200012  781.650024  763.450012  768.700012  768.700012   \n",
       "1  2016-11-03  767.250000  769.950012  759.030029  762.130005  762.130005   \n",
       "2  2016-11-04  750.659973  770.359985  750.560974  762.020020  762.020020   \n",
       "3  2016-11-07  774.500000  785.190002  772.549988  782.520020  782.520020   \n",
       "4  2016-11-08  783.400024  795.632996  780.190002  790.510010  790.510010   \n",
       "\n",
       "    Volume  \n",
       "0  1872400  \n",
       "1  1943200  \n",
       "2  2134800  \n",
       "3  1585100  \n",
       "4  1350800  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/GOOG-year.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.112708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.160459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.112708\n",
       "1  0.090008\n",
       "2  0.089628\n",
       "3  0.160459\n",
       "4  0.188066"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test\n",
    "\n",
    "I will cut the dataset to train and test datasets,\n",
    "\n",
    "1. Train dataset derived from starting timestamp until last 30 days\n",
    "2. Test dataset derived from last 30 days until end of the dataset\n",
    "\n",
    "So we will let the model do forecasting based on last 30 days, and we will going to repeat the experiment for 10 times. You can increase it locally if you want, and tuning parameters will help you by a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((252, 7), (222, 1), (30, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 30\n",
    "simulation_size = 10\n",
    "\n",
    "df_train = df_log.iloc[:-test_size]\n",
    "df_test = df_log.iloc[-test_size:]\n",
    "df.shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(inputs):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    repr_dim = inputs.get_shape()[-1].value\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1])\n",
    "\n",
    "def layer_norm(inputs, epsilon=1e-8):\n",
    "    mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n",
    "    normalized = (inputs - mean) / (tf.sqrt(variance + epsilon))\n",
    "    params_shape = inputs.get_shape()[-1:]\n",
    "    gamma = tf.get_variable('gamma', params_shape, tf.float32, tf.ones_initializer())\n",
    "    beta = tf.get_variable('beta', params_shape, tf.float32, tf.zeros_initializer())\n",
    "    return gamma * normalized + beta\n",
    "\n",
    "def cnn_block(x, dilation_rate, pad_sz, hidden_dim, kernel_size):\n",
    "    x = layer_norm(x)\n",
    "    pad = tf.zeros([tf.shape(x)[0], pad_sz, hidden_dim])\n",
    "    x =  tf.layers.conv1d(inputs = tf.concat([pad, x, pad], 1),\n",
    "                          filters = hidden_dim,\n",
    "                          kernel_size = kernel_size,\n",
    "                          dilation_rate = dilation_rate)\n",
    "    x = x[:, :-pad_sz, :]\n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        kernel_size = 3,\n",
    "        n_attn_heads = 16,\n",
    "        dropout = 0.9,\n",
    "    ):\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "\n",
    "        encoder_embedded = tf.layers.dense(self.X, size_layer)\n",
    "        encoder_embedded += position_encoding(encoder_embedded)\n",
    "        \n",
    "        e = tf.identity(encoder_embedded)\n",
    "        for i in range(num_layers): \n",
    "            dilation_rate = 2 ** i\n",
    "            pad_sz = (kernel_size - 1) * dilation_rate \n",
    "            with tf.variable_scope('block_%d'%i):\n",
    "                encoder_embedded += cnn_block(encoder_embedded, dilation_rate, \n",
    "                                              pad_sz, size_layer, kernel_size)\n",
    "                \n",
    "        encoder_output, output_memory = encoder_embedded, encoder_embedded + e\n",
    "        g = tf.identity(encoder_embedded)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            dilation_rate = 2 ** i\n",
    "            pad_sz = (kernel_size - 1) * dilation_rate\n",
    "            with tf.variable_scope('decode_%d'%i):\n",
    "                attn_res = h = cnn_block(encoder_embedded, dilation_rate, \n",
    "                                         pad_sz, size_layer, kernel_size)\n",
    "\n",
    "            C = []\n",
    "            for j in range(n_attn_heads):\n",
    "                h_ = tf.layers.dense(h, size_layer // n_attn_heads)\n",
    "                g_ = tf.layers.dense(g, size_layer // n_attn_heads)\n",
    "                zu_ = tf.layers.dense(\n",
    "                    encoder_output, size_layer // n_attn_heads\n",
    "                )\n",
    "                ze_ = tf.layers.dense(output_memory, size_layer // n_attn_heads)\n",
    "\n",
    "                d = tf.layers.dense(h_, size_layer // n_attn_heads) + g_\n",
    "                dz = tf.matmul(d, tf.transpose(zu_, [0, 2, 1]))\n",
    "                a = tf.nn.softmax(dz)\n",
    "                c_ = tf.matmul(a, ze_)\n",
    "                C.append(c_)\n",
    "\n",
    "            c = tf.concat(C, 2)\n",
    "            h = tf.layers.dense(attn_res + c, size_layer)\n",
    "            h = tf.nn.dropout(h, keep_prob = dropout)\n",
    "            encoder_embedded += h\n",
    "\n",
    "        encoder_embedded = tf.sigmoid(encoder_embedded[-1])\n",
    "        self.logits = tf.layers.dense(encoder_embedded, output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = test_size\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "future_day = test_size\n",
    "learning_rate = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], \n",
    "        dropout = dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {modelnn.X: batch_x, modelnn.Y: batch_y},\n",
    "            )        \n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits = sess.run(\n",
    "            modelnn.logits,\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits = sess.run(\n",
    "            modelnn.logits,\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0)\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits = sess.run(\n",
    "            modelnn.logits,\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0)\n",
    "            },\n",
    "        )\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.3)\n",
    "    \n",
    "    return deep_future[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 1\n",
      "WARNING:tensorflow:From C:\\Users\\dev\\AppData\\Local\\Temp/ipykernel_16484/3885788165.py:4: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\dev\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [00:20<00:00, 14.37it/s, acc=97.6, cost=0.00122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [00:22<00:00, 13.18it/s, acc=94.6, cost=0.00647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loop: 100%|██████████| 300/300 [00:21<00:00, 13.91it/s, acc=97.1, cost=0.0018] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation 4\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [calculate_accuracy(df['Close'].iloc[-test_size:].values, r) for r in results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'].iloc[-test_size:].values, label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
